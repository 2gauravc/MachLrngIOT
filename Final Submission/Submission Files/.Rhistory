)
predict(modFit, newdata = data.frame(TotalIntench2 = c(23000,50000,57000,NA), FiberWidthCh1 = c(10,10,8,NA), PerimStatusCh1=c(2,NA,NA,2), VarIntenCh4 =c(NA, 100,100,100)))
library(rattle)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modit$finalModel)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rattle")
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages('rpart.plot')
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
predict(modFit, newdata = data.frame(TotalIntench2 = c(23000,50000,57000,NA), FiberWidthCh1 = c(10,10,8,NA), PerimStatusCh1=c(2,NA,NA,2), VarIntenCh4 =c(NA, 100,100,100)))
set.seed(125)
table(segmentationOriginal$Case)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
modFit <- train(Case~., method = "rpart", data=training)
library(caret)
modFit <- train(Case~., method = "rpart", data=training)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
training<-segmentationOriginal[segmentationOriginal$Case=="Train",]
testing<-segmentationOriginal[segmentationOriginal$Case=="Test",]
set.seed(125)
model<-train(Class ~ .,
data = training,
method = "rpart")
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(model$finalModel)
library(pgmm)
install.pacakges("pgmm")
install.pacakages("pgmm")
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
str(olive)
modFit <- train(Area~., method = "class", data = "olive")
modFit <- train(Area~., method = "class", data = olive)
modFit <- train(Area~., method = "rpart", data = olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit, newdata)
table(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
str(trainSA)
modFit <- train(chd~c("age", "alchohol", "obesity", "tobacco", "typea", "ldl"), method="glm", family="binomial")
modFit <- train(chd~c("age", "alchohol", "obesity", "tobacco", "typea", "ldl"), method="glm", family="binomial", data=trainSA)
modFit <- train(chd~age+alchohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
modFit <- train(chd~age+alchohol+obesity+tobacco+typea+ldl, method="glm", family="binomial", data=trainSA)
model <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd, predict(model, trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(voewl.test)
str(vowel.test)
class(voewl.test$y)
class(vowel.test$y)
vowel.test$y <- as.Factor(vowel.test$y)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
str(vowel.test)
set.seed(33833)
modFit <- train(y ~., method='rf', data=voewl.test)
modFit <- train(y ~., method='rf', data=vowel.test)
varImp(modFit$finalModel)
modFit <- train(y ~., method='rf', data=vowel.train)
varImp(modFit$finalModel)
order(varImp(modelRf), decreasing=T)
order(varImp(modFit), decreasing=T)
varImp(modFit)
modFit <- train(y ~., method='rf', data=vowel.train, prox=TRUE)
setwd("C:/Users/E1-21804G50MNK/Dropbox/Data Analytics/Machine Learning IOT/Raw Code")
training <- read.csv("../Data/pml-training.csv", header=TRUE)
training <- read.csv("../Data/pml-training.csv", header=TRUE)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
dim(testing)
dim(training)
row.names(na_count)
head(na_count)
na_count
na_count[na_count$na_count != 0,]
row.names(na_count[na_count$na_count != 0,])
row.names(na_count)
na_count[na_count$na_count != 0,]
todrop <- if(na_count$na_count>1900, TRUE, FALSE)
todrop <- ifelse(na_count$na_count>1900, TRUE, FALSE)
todrop
sum(todrop)
row.names(na_count[todrop,])
na_count[todrop,]
na_count[na_count$na_count > 1900,]
na_count[na_count$na_count > 1900,, drop=FALSE]
disccols <- row.names(na_count[na_count$na_count >19000,,drop=FALSE])
disccols
dim(training)
training <- training[ , -which(names(training) %in% disccols)] # remove 67 cols with mostly NAs
dim(training)
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
training <- factorsNumeric(training)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
training <- read.csv("../Data/pml-training.csv", header=TRUE)
trainoutcome <- training[,160] # capture outcome before removing it
training <- training[,-c(1:7, 160)] # remove useless vars and outcome
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
disccols <- row.names(na_count[na_count$na_count >19000,,drop=FALSE])
training <- training[ , -which(names(training) %in% disccols)] # remove 67 cols with mostly NAs
dim(training)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
summary(training)
class(training$kurtosis_yaw_dumbbell)
head(training$kurtosis_yaw_dumbbell)
head(training$kurtosis_yaw_dumbbell,10)
training$skewness_yaw_forearm
null_count <-sapply(training, function(y) sum(length(which(is.null(y)))))
null_count <- data.frame(null_count)
null_count
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
training1 <- factorsNumeric(training)
na_count <-sapply(training1, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
disccols <- row.names(na_count[na_count$na_count >19000,,drop=FALSE])
disccols
traning$kurtosis_roll_belt
training$kurtosis_roll_belt
training$skewness_pitch_forearm
training$skewness_roll_arm
training$skewness_roll_arm <- as.numeric(as.character(training$skewness_roll_arm))
training$skewness_roll_arm
training <- read.csv("../Data/pml-training.csv", header=TRUE)
validation <- read.csv("../Data/pml-testing.csv", header=TRUE)
# Clean-up
## remove the user and timestamp variables from training data set
trainoutcome <- training[,160] # capture outcome before removing it
training <- training[,-c(1:7, 160)] # remove useless vars and outcome
## Convert factors to numeric
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
training <- factorsNumeric(training)
# Remove Cols with high number of NAs
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
disccols <- row.names(na_count[na_count$na_count >19000,,drop=FALSE])
training <- training[ , -which(names(training) %in% disccols)] # remove 67 cols with mostly NAs
dim(training)
nsv <- nearZeroVar(training, saveMetrics=TRUE)
library(caret)
library(caret)
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
M <- abs(cor(training))
diag(M) <- 0
which(M>0, arr.ind=T)
prComp <- prcomp (training)
prComp
prComp$x[,1]
prComp$rotation
dim(training)
str(training)
summary(training)
preProc <- preProcess(training, method="pca", thresh=0.95)
preProc
preProc <- preProcess(training, method="pca", thresh=0.90)
preProc
preProc <- preProcess(training, method="pca", thresh=0.85)
preProc
preProc <- preProcess(training, method="pca", thresh=0.90)
summary(training)
hist(training[,1])
hist(training[,2])
hist(training[,3])
hist(training[,4])
signedlog10 = function(x) {
ifelse(abs(x) <= 1, 0, sign(x)*log10(abs(x)))
}
hist(signedlog10(training[,4])
)
hist(signedlog10(training[,1]))
hist(training[,1])
str(prComp)
prComp
preProc
pred <- predict(preProc, training)
plot(pred[,1], pred[,2], col=trainoutcome)
trainPC <- predict(preProc, training)
modFit <- traing(training$classe ~ ., method = "glm", data=trainPC)
training$classe <- trainoutcome
modFit <- train(training$classe ~ ., method = "glm", data=trainPC)
dim(training)
warnings()
modFit <- train(training$classe ~ ., method = "rf", data=trainPC)
hist(training[,1])
hist(training[,2])
hist(training[,3])
preProc <- preProcess(training, method=c("BoxCox", "center", "scale", "pca"), thresh=0.90)
training <- read.csv("../Data/pml-training.csv", header=TRUE)
validation <- read.csv("../Data/pml-testing.csv", header=TRUE)
# Clean-up
## remove the user and timestamp variables from training data set
trainoutcome <- training[,160] # capture outcome before removing it
training <- training[,-c(1:7, 160)] # remove useless vars and outcome
## Convert factors to numeric
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
training <- factorsNumeric(training)
## Remove Cols with high number of NAs (>19000 NAs)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
disccols <- row.names(na_count[na_count$na_count >19000,,drop=FALSE])
training <- training[ , -which(names(training) %in% disccols)] # remove cols with mostly NAs
# Covariate Creation
## Check for near Zero Vars
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
preProc <- preProcess(training, method=c("BoxCox", "center", "scale", "pca"), thresh=0.90)
trainPC <- predict(preProc, training)
plot(trainPC[,1], trainPC[,2], col=trainoutcome)
training$classe <- trainoutcome
modFit <- train(training$classe ~ ., method = "rpart", data=trainPC)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
training$classe
table(training$classe)
library(caret)
library(rattle)
iotdata <- read.csv("../Data/pml-training.csv", header=TRUE)
inTrain <- createDataPartition(y=iotdata$classe, p=0.7, list=FALSE)
training <- iotdata[inTrain,]
testing <- iotdata[-inTrain,]
## remove the user and timestamp variables from training data set
trainoutcome <- training$classe # capture outcome before removing it
training <- training[,-c(1:7, 160)] # remove useless vars and outcome
## Convert factors to numeric
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
training <- factorsNumeric(training)
## Remove Cols with high number of NAs (>19000 NAs)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
disccols <- row.names(na_count[na_count$na_count >19000,,drop=FALSE])
training <- training[ , -which(names(training) %in% disccols)] # remove cols with mostly NAs
# Covariate Creation
## Check for near Zero Vars
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
dim(training)
iotdata <- read.csv("../Data/pml-training.csv", header=TRUE)
inTrain <- createDataPartition(y=iotdata$classe, p=0.7, list=FALSE)
training <- iotdata[inTrain,]
testing <- iotdata[-inTrain,]
dim(training)
dim(testing)
trainoutcome <- training$classe
training <- training[,-c(1:7, 160)]
dim(training)
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
training <- factorsNumeric(training)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
na_count
disccols <- row.names(na_count[na_count$na_count >80%*nrow(training),,drop=FALSE])
disccols <- row.names(na_count[na_count$na_count > 0.8*nrow(training),,drop=FALSE])
disccols
na_count
dim(training)
str(disccols)
training <- training[ , -which(names(training) %in% disccols)] # remove cols with mostly NAs
dim(training)
preProc <- preProcess(training, method=c("BoxCox", "center", "scale", "pca"), thresh=0.90)
trainPC <- predict(preProc, training)
plot(trainPC[,1], trainPC[,2], col=trainoutcome)
training$classe <- trainoutcome
modFit <- train(training$classe ~ ., method = "rpart", data=trainPC)
fancyRpartPlot(modFit$finalModel)
p <- predict(modFit, newdata=testing)
testPC <- predict(preProc, testing)
warnings()
iotdata <- read.csv("../Data/pml-training.csv", header=TRUE)
inTrain <- createDataPartition(y=iotdata$classe, p=0.7, list=FALSE)
training <- iotdata[inTrain,]
testing <- iotdata[-inTrain,]
# Clean-up
## remove the user and timestamp variables from training data set
trainoutcome <- training$classe # capture outcome before removing it
training <- training[,-c(1:7, 160)] # remove useless vars and outcome
## Convert factors to numeric
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],
asNumeric))
training <- factorsNumeric(training)
## Remove Cols with high number of NAs (>19000 NAs)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
disccols <- row.names(na_count[na_count$na_count > 0.8*nrow(training),,drop=FALSE])
training <- training[ , -which(names(training) %in% disccols)] # remove cols with mostly NAs
# Covariate Creation
## Check for near Zero Vars
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
dim(training)
preProc <- preProcess(training, method="pca", thresh=0.90)
trainPC <- predict(preProc, training)
plot(trainPC[,1], trainPC[,2], col=trainoutcome)
training$classe <- trainoutcome
modFit1 <- train(training$classe ~ ., method = "rpart", data=trainPC)
fancyRpartPlot(modFit$finalModel)
testoutcome <- testing$classe # capture test outcome before removing it
testing <- testing[,-c(1:7, 160)] # remove useless vars and outcome
testing <- testing[ , -which(names(training) %in% disccols)] # remove cols with mostly NAs
testPC <- predict(preProc, testing)
testing$classe <- testoutcome
testing <- iotdata[-inTrain,]
testoutcome <- testing$classe # capture test outcome before removing it
testing <- testing[,-c(1:7, 160)] # remove useless vars and outcome
testing <- testing[ , -which(names(training) %in% disccols)] # remove cols with mostly NAs in training set
dim(testing)
disccols
str(testing)
testing <- iotdata[-inTrain,]
dim(testing)
names(testing)
names(training)
discols
disccols
testing <- testing[ , -which(names(testing) %in% disccols)] # remove cols with mostly NAs in training set
dim(testing)
dim(training)
testing <- iotdata[-inTrain,]
dim(testing)
testoutcome <- testing$classe # capture test outcome before removing it
testing <- testing[,-c(1:7, 160)] # remove useless vars and outcome
dim(testing)
disccols
testing <- testing[ , -which(names(testing) %in% disccols)] # remove cols with mostly NAs in training set
dim(testing)
testPC <- predict(preProc, testing)
testing$classe <- testoutcome
p1 <- predict(modFit1, newdata=testing)
str(testPC)
str(trainPC)
p1 <- predict(modFit1, newdata=testPC)
confusionMatrix(p1, testing$classe)
modFit2 <- train(training$classe ~ ., method = "rf", data=trainPC)
modFit2 <- train(training$classe ~ ., method = "rf", data=trainPC)
modFit2
testing <- iotdata[-inTrain,]
testoutcome <- testing$classe # capture test outcome before removing it
testing <- testing[,-c(1:7, 160)] # remove useless vars and outcome
testing <- testing[ , -which(names(testing) %in% disccols)] # remove cols with mostly NAs in training set
dim(testing)
testPC <- predict(preProc, testing)
testing$classe <- testoutcome
p2 <- predict(modFit2, newdata=testPC)
p2
confusionMatrix(testing$classe, p2)
validation = read.csv("../Data/pml-testing.csv", header=TRUE)
# Perform the transformation operations on this set
valoutcome <- validation$classe # capture test outcome before removing it
validation <- validation[,-c(1:7, 160)] # remove useless vars and outcome
validation <- validation[ , -which(names(validation) %in% disccols)] # remove cols with mostly NAs in training set
# PCA
validationPC <- predict(preProc, validation)
validation$classe <- testoutcome
validation = read.csv("../Data/pml-testing.csv", header=TRUE)
# Perform the transformation operations on this set
valoutcome <- validation$classe # capture test outcome before removing it
validation <- validation[,-c(1:7, 160)] # remove useless vars and outcome
validation <- validation[ , -which(names(validation) %in% disccols)] # remove cols with mostly NAs in training set
# PCA
validationPC <- predict(preProc, validation)
validation$classe <- valoutcome
p2 <- predict(modFit1, newdata=validationPC)
p2
p2 <- predict(modFit2, newdata=validationPC)
p2
length(p2)
answers <- p2
setwd("C:/Users/E1-21804G50MNK/Dropbox/Data Analytics/Machine Learning IOT/Raw Code")
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0("problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}
getwd()
setwd("../Submission Files/")
pml_write_files(answers)
?randomForest
library(caret)
library(rattle)
iotdata <- read.csv("../Data/pml-training.csv", header=TRUE)
inTrain <- createDataPartition(y=iotdata$classe, p=0.7, list=FALSE)
training <- iotdata[inTrain,]
testing <- iotdata[-inTrain,]
## 1. remove the user and timestamp variables from training data set
trainoutcome <- training$classe # capture outcome before removing it
training <- training[,-c(1:7, 160)] # remove useless vars and outcome
## Convert factors to numeric
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(d) modifyList(d, lapply(d[, sapply(d, is.factor)],                                     asNumeric))
training <- factorsNumeric(training)
## Remove Cols with high number of NAs (>80% NAs)
na_count <-sapply(training, function(y) sum(length(which(is.na(y)))))
na_count <- data.frame(na_count)
disccols <- row.names(na_count[na_count$na_count > 0.8*nrow(training),,drop=FALSE])
training <- training[ , -which(names(training) %in% disccols)] # remove cols with mostly NAs
ncol(training)
nsv <- nearZeroVar(training, saveMetrics=TRUE)
nsv
M <- abs(cor(training[,-c(1:7,160)]))
diag(M) <- 0
which(M>0, arr.ind=T)
# Apply PCA
preProc <- preProcess(training, method="pca", thresh=0.90)
preProc
trainPC <- predict(preProc, training)
training$classe <- trainoutcome
modFit1 <- train(training$classe ~ ., method = "rpart", data=trainPC)
str(modFit1)
modFit1$results
str(training)
str(trainPC)
modFt2 <- randomForest(y=training$classe, x = trainPC, ntree=10000, do.trace=T)
help(memory.size)
modFt2 <- randomForest(y=training$classe, x = trainPC, ntree=1000, do.trace=T)
modFt2$results
p1 <- predict(modFit2, newdata=trainPC)
p1 <- predict(modFt2, newdata=trainPC)
confusionMatrix(training$classe, p2)
confusionMatrix(training$classe, p1)
p1
str(p1)
p1 <- as.data.frame(p1)
str(p1)
table(p1$p1)
table(training$classe)
testoutcome <- testing$classe # capture test outcome before removing it
testing <- testing[,-c(1:7, 160)] # remove useless vars and outcome
testing <- testing[ , -which(names(testing) %in% disccols)] # remove cols with mostly NAs in training set
testPC <- predict(preProc, testing)
testing$classe <- testoutcome
p2 <- predict(modFt2, newdata=testPC)
confusionMatrix(testing$classe, p2)
valoutcome <- validation$classe # capture test outcome before removing it
validation <- validation[,-c(1:7, 160)] # remove useless vars and outcome
validation <- validation[ , -which(names(validation) %in% disccols)] # remove cols with mostly NAs in training set
validation = read.csv("../Data/pml-testing.csv", header=TRUE)
# Perform the transformation operations on this set
valoutcome <- validation$classe # capture test outcome before removing it
validation <- validation[,-c(1:7, 160)] # remove useless vars and outcome
validation <- validation[ , -which(names(validation) %in% disccols)] # remove cols with mostly NAs in training set
# PCA on the validation setusing preProc object from training set
validationPC <- predict(preProc, validation)
validation$classe <- valoutcome
p2 <- predict(modFit2, newdata=validationPC)
p2 <- predict(modFt2, newdata=validationPC)
p2
library(randomForest)
iotdata <- read.csv("../Data/pml-training.csv", header=TRUE)
str(iotdata)
fancyRpartPlot(modFit1)
fancyRpartPlot(modFit1$finaModel)
fancyRpartPlot(modFit1$finalModel)
